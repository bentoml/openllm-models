envs:
- name: HF_TOKEN
include:
- '*.py'
- '*.yaml'
- ui/*
- ui/chunks/*
- ui/css/*
- ui/media/*
- ui/chunks/pages/*
- bentovllm_openai/*.py
- chat_templates/chat_templates/*.jinja
- chat_templates/generation_configs/*.json
labels:
  model_name: mistralai/Mistral-Large-Instruct-2407
  openllm_alias: 123b, 123b-instruct-2407
  platforms: linux
  source: https://github.com/bentoml/openllm-models-feed/tree/main/src/vllm-chat
python:
  lock_packages: true
  requirements_txt: ./requirements.txt
service: service:VLLM
