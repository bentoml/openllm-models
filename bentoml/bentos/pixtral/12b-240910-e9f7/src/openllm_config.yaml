engine_config:
  enable_chunked_prefill: false
  enable_prefix_caching: true
  limit_mm_per_prompt:
    image: 1
  max_model_len: 16384
  model: mistral-community/pixtral-12b-240910
  tokenizer_mode: mistral
extra_labels:
  model_name: mistral-community/pixtral-12b-240910
  openllm_alias: 12b, 12b-vision
extra_requirements:
- mistral_common[opencv]
project: vllm-chat
server_config:
  chat_template: "{% if messages[0]['role'] == 'system' %}\n    {% set loop_messages\
    \ = messages[1:] %}\n    {% set system_message = messages[0]['content'].strip()\
    \ + '\\n\\n' %}\n{% else %}\n    {% set loop_messages = messages %}\n    {% set\
    \ system_message = '' %}\n{% endif %}\n\n{{ bos_token }}\n{% for message in loop_messages\
    \ %}\n    {% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}\n   \
    \     {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...')\
    \ }}\n    {% endif %}\n\n    {% if loop.index0 == 0 %}\n        {% set content\
    \ = system_message + message['content'] %}\n    {% else %}\n        {% set content\
    \ = message['content'] %}\n    {% endif %}\n\n    {% if message['role'] == 'user'\
    \ %}\n        {{ '[INST] ' + content.strip() + ' [/INST]' }}\n    {% elif message['role']\
    \ == 'assistant' %}\n        {{ ' ' + content.strip() + eos_token }}\n    {% endif\
    \ %}\n{% endfor %}\n"
service_config:
  name: pixtral
  resources:
    gpu: 1
    gpu_type: nvidia-a100-80gb
  traffic:
    timeout: 300
vision: true
