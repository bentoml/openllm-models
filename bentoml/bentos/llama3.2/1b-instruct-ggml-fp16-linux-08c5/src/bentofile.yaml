envs:
- name: CMAKE_ARGS
  value: -DGGML_BLAS=ON -DGGML_BLAS_VENDOR=OpenBLAS
include:
- '*.py'
- '*.yaml'
- '*.txt'
- ui/*
labels:
  model_name: unsloth/Llama-3.2-1B-Instruct-GGUF
  openllm_alias: llama3.2,1b-instruct-ggml-fp16-linux
  platforms: linux
  source: https://github.com/bentoml/openllm-models/tree/main/src/llamacpp-chat
python:
  lock_packages: true
  requirements_txt: ./requirements.txt
service: service:LlamaCppChat
