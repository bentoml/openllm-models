engine_config:
  additional_files:
  - qwen2.5-32b-instruct-00001-of-00017.gguf
  - qwen2.5-32b-instruct-00002-of-00017.gguf
  - qwen2.5-32b-instruct-00003-of-00017.gguf
  - qwen2.5-32b-instruct-00004-of-00017.gguf
  - qwen2.5-32b-instruct-00005-of-00017.gguf
  - qwen2.5-32b-instruct-00006-of-00017.gguf
  - qwen2.5-32b-instruct-00007-of-00017.gguf
  - qwen2.5-32b-instruct-00008-of-00017.gguf
  - qwen2.5-32b-instruct-00009-of-00017.gguf
  - qwen2.5-32b-instruct-00010-of-00017.gguf
  - qwen2.5-32b-instruct-00011-of-00017.gguf
  - qwen2.5-32b-instruct-00012-of-00017.gguf
  - qwen2.5-32b-instruct-00013-of-00017.gguf
  - qwen2.5-32b-instruct-00014-of-00017.gguf
  - qwen2.5-32b-instruct-00015-of-00017.gguf
  - qwen2.5-32b-instruct-00016-of-00017.gguf
  - qwen2.5-32b-instruct-00017-of-00017.gguf
  filename: qwen2.5-32b-instruct-00001-of-00017.gguf
  max_model_len: 2048
  repo_id: Qwen/Qwen2.5-32B-Instruct-GGUF
labels:
  platforms: darwin
project: llamacpp-chat
service_config:
  envs:
  - name: CMAKE_ARGS
    value: -DGGML_METAL=on
  name: qwen2.5
  resources:
    memory: 60Gi
  traffic:
    timeout: 300
