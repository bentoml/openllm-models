bentoml==1.3.0
torch==2.3.1
vllm==0.5.3.post1
numpy==1.26.0
transformers==4.43.1
fastapi==0.111.0
pyyaml
--extra-index-url https://flashinfer.ai/whl/cu121/torch2.3
flashinfer
