alias:
- 405b
engine_config:
  max_model_len: 4096
  model: NousResearch/Hermes-3-Llama-3.1-405B-FP8
  tensor_parallel_size: 6
project: vllm-chat
server_config:
  tool_call_parser: pythonic
service_config:
  name: hermes3
  resources:
    gpu: 6
    gpu_type: nvidia-a100-80gb
  traffic:
    timeout: 300
